// ============================================================
// üìò CONCEPT 1: TIME & SPACE COMPLEXITY
// ============================================================
// Understanding how to measure algorithm efficiency
// Before solving ANY DSA problem, you MUST understand this.
// ============================================================

// ============================================================
// üîπ WHAT IS TIME COMPLEXITY?
// ============================================================
// Time Complexity = How the runtime of an algorithm grows
//                   as the input size (n) increases.
//
// We use BIG-O NOTATION to describe this.
// Big-O gives the WORST CASE scenario.
//
// Think of it as: "If I double the input, how much slower does it get?"

// ============================================================
// üîπ COMMON TIME COMPLEXITIES (Best to Worst)
// ============================================================
//
// O(1)        ‚Üí Constant     ‚Üí Doesn't depend on input size
// O(log n)    ‚Üí Logarithmic  ‚Üí Halving the problem each step (Binary Search)
// O(n)        ‚Üí Linear       ‚Üí Visit every element once
// O(n log n)  ‚Üí Linearithmic ‚Üí Efficient sorting (Merge Sort, Quick Sort)
// O(n¬≤)       ‚Üí Quadratic    ‚Üí Nested loops (Bubble Sort)
// O(n¬≥)       ‚Üí Cubic        ‚Üí Triple nested loops
// O(2‚Åø)       ‚Üí Exponential  ‚Üí Recursion without memoization (Fibonacci naive)
// O(n!)       ‚Üí Factorial    ‚Üí Permutations

// ============================================================
// üîπ EXAMPLES OF EACH COMPLEXITY
// ============================================================

// --- O(1) - Constant Time ---
// No matter the size of input, it takes the same time
function getFirst(arr) {
  return arr[0]; // Always 1 operation
}
// Accessing array by index, hash map lookup, push/pop from stack

// --- O(log n) - Logarithmic Time ---
// Problem size is halved each step
function binarySearchExample(arr, target) {
  let left = 0, right = arr.length - 1;
  while (left <= right) {
    let mid = Math.floor((left + right) / 2);
    if (arr[mid] === target) return mid;
    else if (arr[mid] < target) left = mid + 1;
    else right = mid - 1;
  }
  return -1;
}
// Each iteration cuts the search space in half
// For n = 1000, only ~10 steps needed (log‚ÇÇ1000 ‚âà 10)

// --- O(n) - Linear Time ---
// Visit every element once
function findMax(arr) {
  let max = arr[0];
  for (let i = 1; i < arr.length; i++) {
    if (arr[i] > max) max = arr[i];
  }
  return max;
}
// If n doubles, time doubles

// --- O(n log n) - Linearithmic Time ---
// Most efficient comparison-based sorting
function mergeSortExample(arr) {
  if (arr.length <= 1) return arr;
  const mid = Math.floor(arr.length / 2);
  const left = mergeSortExample(arr.slice(0, mid));
  const right = mergeSortExample(arr.slice(mid));
  return merge(left, right);
}
function merge(left, right) {
  const result = [];
  let i = 0, j = 0;
  while (i < left.length && j < right.length) {
    if (left[i] <= right[j]) result.push(left[i++]);
    else result.push(right[j++]);
  }
  return [...result, ...left.slice(i), ...right.slice(j)];
}

// --- O(n¬≤) - Quadratic Time ---
// Nested loops over the same data
function bubbleSort(arr) {
  for (let i = 0; i < arr.length; i++) {       // n times
    for (let j = 0; j < arr.length - 1; j++) { // n times
      if (arr[j] > arr[j + 1]) {
        [arr[j], arr[j + 1]] = [arr[j + 1], arr[j]];
      }
    }
  }
  return arr;
}
// If n doubles, time quadruples!

// --- O(2‚Åø) - Exponential Time ---
// Each call branches into 2 more calls
function fibNaive(n) {
  if (n <= 1) return n;
  return fibNaive(n - 1) + fibNaive(n - 2);
}
// For n = 40, this makes ~1 billion calls!

// --- O(n!) - Factorial Time ---
// Generate all permutations
function permutations(arr, start = 0, result = []) {
  if (start === arr.length) {
    result.push([...arr]);
    return;
  }
  for (let i = start; i < arr.length; i++) {
    [arr[start], arr[i]] = [arr[i], arr[start]];
    permutations(arr, start + 1, result);
    [arr[start], arr[i]] = [arr[i], arr[start]];
  }
  return result;
}

// ============================================================
// üîπ WHAT IS SPACE COMPLEXITY?
// ============================================================
// Space Complexity = How much EXTRA memory does the algorithm use
//                    as the input grows?
//
// We DON'T count the input itself, only EXTRA space.

// --- O(1) Space ---
function sum(arr) {
  let total = 0; // Only 1 variable, regardless of input size
  for (let num of arr) total += num;
  return total;
}

// --- O(n) Space ---
function duplicate(arr) {
  const copy = [...arr]; // Creates a new array of size n
  return copy;
}

// --- O(n) Space (Recursion) ---
function factorial(n) {
  if (n <= 1) return 1;
  return n * factorial(n - 1);
  // Each call adds a frame to the CALL STACK
  // n calls = O(n) space
}

// ============================================================
// üîπ HOW TO CALCULATE TIME COMPLEXITY
// ============================================================
//
// RULES:
// 1. DROP CONSTANTS    ‚Üí O(2n) becomes O(n)
// 2. DROP LOWER TERMS  ‚Üí O(n¬≤ + n) becomes O(n¬≤)
// 3. DIFFERENT INPUTS  ‚Üí Use different variables
//                        O(a + b) NOT O(n)
//
// PATTERNS TO RECOGNIZE:
//
// Single loop            ‚Üí O(n)
// Nested loops (same)    ‚Üí O(n¬≤)
// Loop halving input     ‚Üí O(log n)
// Loop inside loop halve ‚Üí O(n log n)
// Recursive (2 calls)    ‚Üí O(2‚Åø)
// Recursive (1 call)     ‚Üí O(n)

// ============================================================
// üîπ PRACTICAL GUIDE: WHAT'S ACCEPTABLE?
// ============================================================
//
// Given n (input size), what complexity is acceptable?
//
// n ‚â§ 10       ‚Üí O(n!) or O(2‚Åø)    ‚Äî Brute force OK
// n ‚â§ 20       ‚Üí O(2‚Åø)              ‚Äî Backtracking
// n ‚â§ 100      ‚Üí O(n¬≥)              ‚Äî Triple loops
// n ‚â§ 1,000    ‚Üí O(n¬≤)              ‚Äî Double loops
// n ‚â§ 100,000  ‚Üí O(n log n)         ‚Äî Sorting
// n ‚â§ 10‚Å∂      ‚Üí O(n)               ‚Äî Linear scan
// n ‚â§ 10‚Åπ      ‚Üí O(log n) or O(1)   ‚Äî Math/Binary Search
//
// LeetCode typically allows ~10‚Å∏ operations per second.

// ============================================================
// üîπ AMORTIZED TIME COMPLEXITY
// ============================================================
// Some operations are USUALLY fast but OCCASIONALLY slow.
// Example: Dynamic array (ArrayList / JS Array push)
//
// push() is O(1) most of the time
// But when array is full ‚Üí it doubles size ‚Üí copies everything ‚Üí O(n)
// Over n operations, the average per operation is still O(1)
// This is called AMORTIZED O(1)

// ============================================================
// üîπ CHEAT SHEET SUMMARY
// ============================================================
/*
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ DATA STRUCTURE          ‚îÇ ACCESS ‚îÇ SEARCH ‚îÇ INSERT ‚îÇ DELETE ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Array                   ‚îÇ O(1)   ‚îÇ O(n)   ‚îÇ O(n)   ‚îÇ O(n)  ‚îÇ
‚îÇ Stack                   ‚îÇ O(n)   ‚îÇ O(n)   ‚îÇ O(1)   ‚îÇ O(1)  ‚îÇ
‚îÇ Queue                   ‚îÇ O(n)   ‚îÇ O(n)   ‚îÇ O(1)   ‚îÇ O(1)  ‚îÇ
‚îÇ Linked List             ‚îÇ O(n)   ‚îÇ O(n)   ‚îÇ O(1)   ‚îÇ O(1)  ‚îÇ
‚îÇ Hash Table              ‚îÇ ‚Äì      ‚îÇ O(1)   ‚îÇ O(1)   ‚îÇ O(1)  ‚îÇ
‚îÇ Binary Search Tree      ‚îÇ O(logn)‚îÇ O(logn)‚îÇ O(logn)‚îÇO(logn)‚îÇ
‚îÇ Heap                    ‚îÇ ‚Äì      ‚îÇ O(n)   ‚îÇO(logn) ‚îÇO(logn)‚îÇ
‚îÇ Trie                    ‚îÇ ‚Äì      ‚îÇ O(m)   ‚îÇ O(m)   ‚îÇ O(m)  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ SORTING ALGORITHM       ‚îÇ BEST   ‚îÇ AVG    ‚îÇ WORST  ‚îÇ SPACE ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Bubble Sort             ‚îÇ O(n)   ‚îÇ O(n¬≤)  ‚îÇ O(n¬≤)  ‚îÇ O(1)  ‚îÇ
‚îÇ Selection Sort          ‚îÇ O(n¬≤)  ‚îÇ O(n¬≤)  ‚îÇ O(n¬≤)  ‚îÇ O(1)  ‚îÇ
‚îÇ Insertion Sort          ‚îÇ O(n)   ‚îÇ O(n¬≤)  ‚îÇ O(n¬≤)  ‚îÇ O(1)  ‚îÇ
‚îÇ Merge Sort              ‚îÇO(nlogn)‚îÇO(nlogn)‚îÇO(nlogn)‚îÇ O(n)  ‚îÇ
‚îÇ Quick Sort              ‚îÇO(nlogn)‚îÇO(nlogn)‚îÇ O(n¬≤)  ‚îÇO(logn)‚îÇ
‚îÇ Heap Sort               ‚îÇO(nlogn)‚îÇO(nlogn)‚îÇO(nlogn)‚îÇ O(1)  ‚îÇ
‚îÇ Counting Sort           ‚îÇ O(n+k) ‚îÇ O(n+k) ‚îÇ O(n+k) ‚îÇO(n+k)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
*/

console.log("‚úÖ Time & Space Complexity ‚Äî Foundation of DSA!");
